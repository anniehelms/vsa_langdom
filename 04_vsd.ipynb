{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33d03dc-3029-4a09-851a-a5fa17755d0c",
   "metadata": {},
   "source": [
    "# Calculating Density-controlled Vowel Space Area\n",
    "\n",
    "This notebook applies the methodology demonstrated in [Story & Bunton (2017)](https://doi.org/10.1121/1.4983342) for calculating density-controlled vowel space area, ideally for measuring vowel space area across task types or mediums. Formant measures are obtained at 5ms intervals of the vowel duration and then normalized. A (200 x 200) grid is generated and for each point on the grid a density value is obtained, equal to the number of formant data points that fall within a 0.05 radius field-of-view around the grid point. A heatmap is created with scaled density values, showing the relative concentrations of vowel productions. A convex hull measure is taken at several density cut-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e24e333-ad96-409f-a586-c36807e3086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e204eb-9f9d-4ea6-aebc-26a4c5f11d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = pd.read_csv(\"data/spanish_vowels.csv\")\n",
    "english = pd.read_csv(\"data/english_vowels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d67d16-3f50-4f85-83e1-bdab3628d3bf",
   "metadata": {},
   "source": [
    "## Define function to calculate density-controlled vowel space area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cfa1c6-4617-4396-966c-5ffaa0be1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsd(df, vowel_column):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.spatial import ConvexHull\n",
    "    from scipy.spatial import distance\n",
    "    \n",
    "    # get lists of participants in dataset\n",
    "    parts = list(df['Participant'].unique())\n",
    "    vowels_list = list(df[vowel_column].unique())\n",
    "        \n",
    "    # define empty list to fill with participant values in form of dataframes\n",
    "    areas_all = []\n",
    "    \n",
    "    # define necessary functions and global variables\n",
    "    ################################################################################\n",
    "    def rem_outliers(df, vowel_column):\n",
    "        print(\"Removal of outliers:\")\n",
    "        print(\"Initial length: \", len(df))\n",
    "    \n",
    "        # establish 25% and 75% for each formant\n",
    "        f1_qrts = df.groupby(['Participant', vowel_column])[\"F1\"].describe()[['25%', '75%']]\n",
    "        f2_qrts = df.groupby(['Participant', vowel_column])[\"F2\"].describe()[['25%', '75%']]\n",
    "    \n",
    "        # find interquartile range for each formant\n",
    "        f1_qrts['IQR'] = f1_qrts['75%'] - f1_qrts['25%']\n",
    "        f2_qrts['IQR'] = f2_qrts['75%'] - f2_qrts['25%']\n",
    "    \n",
    "        # determine upper limit for each formant\n",
    "        f1_qrts['upper'] = f1_qrts['75%'] + (1.5 * f1_qrts['IQR'])\n",
    "        f2_qrts['upper'] = f2_qrts['75%'] + (1.5 * f2_qrts['IQR'])\n",
    "    \n",
    "        # determine lower limit for each formant\n",
    "        f1_qrts['lower'] = f1_qrts['25%'] - (1.5 * f1_qrts['IQR'])\n",
    "        f2_qrts['lower'] = f2_qrts['25%'] - (1.5 * f2_qrts['IQR'])\n",
    "    \n",
    "        # create smaller df with only limits for each formant\n",
    "        f1_limits = f1_qrts[['upper','lower']]\n",
    "        f2_limits = f2_qrts[['upper','lower']]\n",
    "    \n",
    "        # merge limits into original df\n",
    "        df = df.merge(f1_limits, left_on = [\"Participant\", vowel_column], right_index = True)\n",
    "        df = df.merge(f2_limits, left_on = [\"Participant\", vowel_column], right_index = True, suffixes = (\"_f1\", \"_f2\"))\n",
    "    \n",
    "        # drop rows with outlier formants\n",
    "        df = df[(df[\"F1\"] > df[\"lower_f1\"]) & (df[\"F1\"] < df[\"upper_f1\"])]\n",
    "        df = df[(df[\"F2\"] > df[\"lower_f2\"]) & (df[\"F2\"] < df[\"upper_f2\"])]\n",
    "\n",
    "        print(\"Final length: \", len(df))\n",
    "        return df\n",
    "    \n",
    "    ####################################################################################\n",
    "    # define function to scale all formant measures\n",
    "    def scale_formants(df):\n",
    "        medians = df.groupby([\"Participant\", \"is_stress\"])[[\"F1\", \"F2\"]].median()\n",
    "\n",
    "        df = df.merge(medians, left_on = [\"Participant\", \"is_stress\"], right_index = True, suffixes = (\"\",\"_med\"))\n",
    "        df[\"F1_vsd\"] = (df[\"F1\"]-df[\"F1_med\"])/df[\"F1_med\"]\n",
    "        df[\"F2_vsd\"] = (df[\"F2\"]-df[\"F2_med\"])/df[\"F2_med\"]\n",
    "        \n",
    "        print(\"Formant data scaled\")\n",
    "        return df \n",
    "    \n",
    "    ####################################################################################\n",
    "    \n",
    "    # define variable `grid`\n",
    "    xvalues = np.flip(np.arange(-1., 1.01, 0.01))\n",
    "    yvalues = np.arange(-1., 1.01, 0.01)\n",
    "\n",
    "    grid = [(round(x, 2), round(y,2)) for x in xvalues for y in yvalues]\n",
    "      \n",
    "    #####################################################################################\n",
    "    \n",
    "    # define function get_density\n",
    "    def density(grid, df):\n",
    "        density_dict = {}\n",
    "        for c in grid:\n",
    "            # define x and y coordinate\n",
    "            x = c[0]\n",
    "            y = c[1]\n",
    "    \n",
    "            # define max and min coordinates that form a square of length 0.1 around the coordinate\n",
    "            x_max = x + 0.05\n",
    "            x_min = x - 0.05\n",
    "            y_max = y + 0.05\n",
    "            y_min = y - 0.05\n",
    "    \n",
    "            # pull a subset of data that fall within the box\n",
    "            opts = df[(df[\"F2_vsd\"] <= x_max) &\n",
    "               (df[\"F2_vsd\"] >= x_min) &\n",
    "               (df[\"F1_vsd\"] <= y_max) &\n",
    "               (df[\"F1_vsd\"] >= y_min)].copy()\n",
    "            opts_list = list(zip(opts[\"F2_vsd\"], opts[\"F1_vsd\"]))\n",
    "    \n",
    "             # define density for this point\n",
    "            dens = 0\n",
    "    \n",
    "            for o in opts_list:\n",
    "                # define x and y coordinate of each point in my data\n",
    "                o_x = o[0]\n",
    "                o_y = o[1]\n",
    "        \n",
    "                # calculate distance to grid point\n",
    "                dist = distance.euclidean([x, y], [o_x, o_y])\n",
    "        \n",
    "                if dist <= 0.05:\n",
    "                    dens += 1\n",
    "        \n",
    "            density_dict[c] = dens\n",
    "    \n",
    "        # convert to df\n",
    "        density_df = pd.DataFrame(density_dict.items())\n",
    "        density_df = density_df.rename(columns = {0: \"coord\", 1:\"density\"})\n",
    "    \n",
    "        # make grid into df\n",
    "        grid_df = pd.DataFrame(grid, columns=[\"x\", \"y\"])\n",
    "        grid_df[\"coord\"] = list(zip(grid_df[\"x\"], grid_df[\"y\"]))\n",
    "    \n",
    "        # join df and grid_df\n",
    "        grid_df = grid_df.join(density_df.set_index('coord'), on=\"coord\")\n",
    "              \n",
    "        return grid_df\n",
    "    \n",
    "    ##################################################################################\n",
    "    # remove outliers by participant, by task, by vowel\n",
    "    df = rem_outliers(df, vowel_column)\n",
    "    \n",
    "    # Lobanov normalization of formants, by participant by task\n",
    "    df = scale_formants(df)\n",
    "    \n",
    "    for i in parts:\n",
    "        print(\"\\n\",i)\n",
    "        \n",
    "        # get subset of data for speaker across modality\n",
    "        df_stress = df[(df[\"Participant\"]==i) & (df[\"is_stress\"]== 1)].copy()\n",
    "        df_unstress = df[(df[\"Participant\"]==i) & (df[\"is_stress\"]== 0)].copy()  \n",
    "           \n",
    "        # get density for each point across the modalities\n",
    "        grid_stress_df = density(grid, df_stress)\n",
    "        print(\"Densities calculated for stressed vowels\")\n",
    "        grid_unstress_df = density(grid, df_unstress)\n",
    "        print(\"Densities calculated for unstressed vowels\")\n",
    "              \n",
    "        # scale density measures\n",
    "        grid_stress_df[\"density_norm\"] = grid_stress_df[\"density\"].apply(lambda x: x/grid_stress_df[\"density\"].max())\n",
    "        grid_unstress_df[\"density_norm\"] = grid_unstress_df[\"density\"].apply(lambda x: x/grid_unstress_df[\"density\"].max())\n",
    "        \n",
    "        # pull out coordinates at various density cutoffs and get areas\n",
    "        cutoffs = [0.10, 0.15, 0.20, 0.25, 0.3]\n",
    "\n",
    "        areas_list = []\n",
    "\n",
    "        for c in cutoffs:\n",
    "            grid_stress_density = grid_stress_df[grid_stress_df[\"density_norm\"] >= c].copy()\n",
    "            grid_unstress_density = grid_unstress_df[grid_unstress_df[\"density_norm\"] >= c].copy()\n",
    "    \n",
    "            points_tuples_stress = list(grid_stress_density[\"coord\"])\n",
    "            points_tuples_unstress = list(grid_unstress_density[\"coord\"])\n",
    "    \n",
    "            points_stress = [list(k) for k in points_tuples_stress]\n",
    "            points_unstress = [list(k) for k in points_tuples_unstress]\n",
    "    \n",
    "            hull_stress = ConvexHull(points_stress)\n",
    "            hull_unstress = ConvexHull(points_unstress)\n",
    "    \n",
    "            area_stress = hull_stress.area\n",
    "            area_unstress = hull_unstress.area\n",
    "\n",
    "            areas = {\"is_stress\": [1, 0], \"Area\": [area_stress, area_unstress], \"Cutoff\": c}\n",
    "            areas_list.append(areas)\n",
    "            \n",
    "        # to show progress while running, print areas at density cutoff of 0.25\n",
    "        print(\"Stress, unstress areas at 0.25 cutoff are: \", areas_list[3][\"Area\"])\n",
    "        \n",
    "        # generate dataframe for this participant and reformat\n",
    "        areas_df = pd.DataFrame(areas_list)\n",
    "        areas_df_stress = areas_df.explode('is_stress')\n",
    "        areas_df_stress = areas_df_stress.drop([\"Area\", \"Cutoff\"], axis = 1)\n",
    "        areas_df_area = areas_df.explode('Area')\n",
    "        areas_df_area = areas_df_area.drop(\"is_stress\", axis = 1)\n",
    "        areas_df = pd.concat([areas_df_stress, areas_df_area], axis = 1)\n",
    "        areas_df[\"Participant\"] = i\n",
    "\n",
    "        # append dataframe to list of dataframes\n",
    "        areas_all.append(areas_df)\n",
    " \n",
    "    # return dataframe of areas\n",
    "    areas_to_return = pd.concat(areas_all)\n",
    "    \n",
    "    return areas_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64a2882d-17fd-48f0-bf06-15ee973d6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of outliers:\n",
      "Initial length:  355115\n",
      "Final length:  324111\n",
      "Formant data scaled\n",
      "\n",
      " p111\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.5524433175361674, 2.7128532528829874]\n",
      "\n",
      " p113\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.6301294587911466, 2.1054029973381465]\n",
      "\n",
      " p114\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.666707564899484, 2.3660280216394174]\n",
      "\n",
      " p117\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.915201082725338, 3.0106180586550755]\n",
      "\n",
      " p118\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.858556038286394, 3.0197287305961265]\n",
      "\n",
      " p119\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.5694565489996277, 3.0209626585575706]\n",
      "\n",
      " p120\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.989894996068776, 2.8008782502763254]\n",
      "\n",
      " p121\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.2666274504880777, 3.1603670381604347]\n",
      "\n",
      " p122\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.8380424693231587, 2.9912022379580145]\n",
      "\n",
      " p123\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.240118188862711, 1.980087195951907]\n",
      "\n",
      " p124\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [1.6159283205576116, 1.9557107695050866]\n",
      "\n",
      " p126\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [1.953156038368953, 1.5222843704779068]\n",
      "\n",
      " s001\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.3973038964770947, 2.7704639865510123]\n",
      "\n",
      " s002\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.7397443488647966, 2.7844693679518264]\n",
      "\n",
      " s051\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.245300045869665, 3.0105430889154667]\n",
      "\n",
      " s053\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.2184843501064284, 3.4730444011048043]\n",
      "\n",
      " s055\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.1784900439398642, 2.2425208956889042]\n",
      "\n",
      " s056\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.844987788363107, 3.2245064627011266]\n"
     ]
    }
   ],
   "source": [
    "spa_vsd = vsd(spanish, \"Vowel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29ab801-6e57-452a-a60d-117dda8d5a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removal of outliers:\n",
      "Initial length:  16524\n",
      "Final length:  15453\n",
      "Formant data scaled\n",
      "\n",
      " p111\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.0763469208390757, 2.1789235534106774]\n",
      "\n",
      " p113\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.7572730610212806, 2.7397367513194633]\n",
      "\n",
      " p114\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.3373550060606427, 2.1201743716229857]\n",
      "\n",
      " p117\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.0600573159516746, 3.4594645761921505]\n",
      "\n",
      " p118\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.570705075097101, 2.240494517139016]\n",
      "\n",
      " p120\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [4.26499401171259, 1.9999281150934574]\n",
      "\n",
      " p121\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.43765177119438, 3.0323565907368493]\n",
      "\n",
      " p122\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.646371534721039, 2.6845836541430095]\n",
      "\n",
      " p123\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.304366072960754, 2.7324251771604295]\n",
      "\n",
      " p124\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [4.205075973845043, 3.1015874075859036]\n",
      "\n",
      " p126\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [2.9045029552721693, 2.127020773659901]\n",
      "\n",
      " p119\n",
      "Densities calculated for stressed vowels\n",
      "Densities calculated for unstressed vowels\n",
      "Stress, unstress areas at 0.25 cutoff are:  [3.0668335221741065, 2.3786187315325367]\n"
     ]
    }
   ],
   "source": [
    "eng_vsd = vsd(english, \"Vowel_bare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717abb9f-7a9a-465b-b9d4-fe31f2b70e34",
   "metadata": {},
   "source": [
    "Add in demographic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b59ae12-d50c-475e-bc01-4c550020afb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_stress</th>\n",
       "      <th>Area</th>\n",
       "      <th>Cutoff</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.017514</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.348619</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.508462</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.990106</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.429103</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_stress      Area  Cutoff Participant Dom\n",
       "0         1  4.017514    0.10        p111  L2\n",
       "1         0  3.348619    0.10        p111  L2\n",
       "2         1  3.508462    0.15        p111  L2\n",
       "3         0  2.990106    0.15        p111  L2\n",
       "4         1  3.429103    0.20        p111  L2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dom = pd.DataFrame({\"Participant\": ['p111', 'p113', 'p114', 'p117','p118', 'p119', 'p120', 'p121', 'p122', 'p123', 'p124', 'p126'],\n",
    "                       \"Dom\": [\"L2\", \"biling\", \"biling\", \"L2\", \"biling\", \"biling\", \"biling\", \"L2\", \"biling\", \"L2\", \"biling\", \"L2\"]})\n",
    "eng_vsd = eng_vsd.merge(eng_dom, on = [\"Participant\"])\n",
    "eng_vsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fad6ab-0789-4fa4-9a1a-7a5a34f918ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_stress</th>\n",
       "      <th>Area</th>\n",
       "      <th>Cutoff</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.302681</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.539401</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.032504</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.023459</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.816748</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_stress      Area  Cutoff Participant Dom\n",
       "0         1  3.302681    0.10        p111  L2\n",
       "1         0  3.539401    0.10        p111  L2\n",
       "2         1  3.032504    0.15        p111  L2\n",
       "3         0  3.023459    0.15        p111  L2\n",
       "4         1  2.816748    0.20        p111  L2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_dom = pd.DataFrame({\"Participant\": ['p111', 'p113', 'p114', 'p117','p118', 'p119', 'p120', 'p121', 'p122', 'p123', 'p124', 'p126', 's051', 's053', 's055', 's056', 's001', 's002'],\n",
    "                       \"Dom\": [\"L2\", \"biling\", \"biling\", \"L2\", \"biling\", \"biling\", \"biling\", \"L2\", \"biling\", \"L2\", \"biling\", \"L2\", \"mono\", \"mono\", \"mono\", \"mono\", \"mono\", \"mono\"]})\n",
    "spa_vsd = spa_vsd.merge(spa_dom, on=[\"Participant\"])\n",
    "spa_vsd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b36544-c09a-42d8-9b5c-130660f89435",
   "metadata": {},
   "source": [
    "Add in average duration of phones by speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ea5f0e-8322-4bc0-8119-3052720d0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>avg_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p111</td>\n",
       "      <td>0.120470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p113</td>\n",
       "      <td>0.136585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p114</td>\n",
       "      <td>0.158571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p117</td>\n",
       "      <td>0.110605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p118</td>\n",
       "      <td>0.113432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   avg_dur\n",
       "0        p111  0.120470\n",
       "1        p113  0.136585\n",
       "2        p114  0.158571\n",
       "3        p117  0.110605\n",
       "4        p118  0.113432"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_vowels = pd.read_csv(\"data/spanish_vowels.csv\")\n",
    "spadur = pd.DataFrame(spa_vowels.groupby([\"Participant\"])[\"avg_dur\"].mean())\n",
    "spadur = spadur.reset_index(drop = False)\n",
    "spadur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eafe2555-c802-4186-b142-4b850cd59ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_stress</th>\n",
       "      <th>Area</th>\n",
       "      <th>Cutoff</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dom</th>\n",
       "      <th>avg_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.302681</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.539401</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.032504</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.023459</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.816748</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_stress      Area  Cutoff Participant Dom  avg_dur\n",
       "0         1  3.302681    0.10        p111  L2  0.12047\n",
       "1         0  3.539401    0.10        p111  L2  0.12047\n",
       "2         1  3.032504    0.15        p111  L2  0.12047\n",
       "3         0  3.023459    0.15        p111  L2  0.12047\n",
       "4         1  2.816748    0.20        p111  L2  0.12047"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_vsd = spa_vsd.merge(spadur, on=[\"Participant\"])\n",
    "spa_vsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "965e53b3-c68f-4fa4-bbf0-26181993205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>avg_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p111</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p113</td>\n",
       "      <td>0.148272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p114</td>\n",
       "      <td>0.176165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p117</td>\n",
       "      <td>0.130144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p118</td>\n",
       "      <td>0.133981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   avg_dur\n",
       "0        p111  0.121433\n",
       "1        p113  0.148272\n",
       "2        p114  0.176165\n",
       "3        p117  0.130144\n",
       "4        p118  0.133981"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vowels = pd.read_csv(\"data/english_vowels.csv\")\n",
    "engdur = pd.DataFrame(eng_vowels.groupby([\"Participant\"])[\"avg_dur\"].mean())\n",
    "engdur = engdur.reset_index(drop = False)\n",
    "engdur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be5de4a-ca3b-460a-9463-ebd811063062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_stress</th>\n",
       "      <th>Area</th>\n",
       "      <th>Cutoff</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dom</th>\n",
       "      <th>avg_dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.017514</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.348619</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.508462</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.990106</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3.429103</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_stress      Area  Cutoff Participant Dom   avg_dur\n",
       "0         1  4.017514    0.10        p111  L2  0.121433\n",
       "1         0  3.348619    0.10        p111  L2  0.121433\n",
       "2         1  3.508462    0.15        p111  L2  0.121433\n",
       "3         0  2.990106    0.15        p111  L2  0.121433\n",
       "4         1  3.429103    0.20        p111  L2  0.121433"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vsd = eng_vsd.merge(engdur, on=[\"Participant\"])\n",
    "eng_vsd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5715ab83-1cb8-47e0-bdcb-1c11de00ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_vsd.to_csv(\"data/spa_areas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a147c0d-1b78-43ab-91db-bb71897a0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vsd.to_csv(\"data/eng_areas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f3ccb2-971a-46c9-bf18-8aa65869795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_stress</th>\n",
       "      <th>Area</th>\n",
       "      <th>Cutoff</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Dom</th>\n",
       "      <th>avg_dur</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>3.301232</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p119</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.141896</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>2.848389</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p118</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.113432</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2.832535</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p111</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.121433</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>3.646372</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p122</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.139943</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>4.267161</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p113</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>3.68368</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p113</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000076</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p113</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2.630129</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p113</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.136585</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>2.127021</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p126</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.143693</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>2.242783</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p122</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.139943</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>4.586473</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p120</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.140621</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>3.900084</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p122</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.139943</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>3.13751</td>\n",
       "      <td>0.20</td>\n",
       "      <td>p119</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.126013</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>3.463852</td>\n",
       "      <td>0.15</td>\n",
       "      <td>p123</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.131732</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>2.858556</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p118</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.113432</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>3.780527</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p121</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.153949</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>3.101587</td>\n",
       "      <td>0.25</td>\n",
       "      <td>p124</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.115026</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>4.063463</td>\n",
       "      <td>0.10</td>\n",
       "      <td>p117</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.110605</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>3.106921</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p123</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.131732</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>3.768125</td>\n",
       "      <td>0.30</td>\n",
       "      <td>p120</td>\n",
       "      <td>biling</td>\n",
       "      <td>0.140621</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_stress      Area  Cutoff Participant     Dom   avg_dur Language\n",
       "53          0  3.301232    0.15        p119  biling  0.141896  Spanish\n",
       "49          0  2.848389    0.30        p118  biling  0.113432  Spanish\n",
       "8           1  2.832535    0.30        p111      L2  0.121433  English\n",
       "76          1  3.646372    0.25        p122  biling  0.139943  English\n",
       "12          1  4.267161    0.15        p113  biling  0.148272  English\n",
       "18          1   3.68368    0.30        p113  biling  0.148272  English\n",
       "19          0  2.000076    0.30        p113  biling  0.136585  Spanish\n",
       "16          1  2.630129    0.25        p113  biling  0.136585  Spanish\n",
       "107         0  2.127021    0.25        p126      L2  0.143693  English\n",
       "78          1  2.242783    0.30        p122  biling  0.139943  English\n",
       "60          1  4.586473    0.10        p120  biling  0.140621  Spanish\n",
       "74          1  3.900084    0.20        p122  biling  0.139943  English\n",
       "114         1   3.13751    0.20        p119  biling  0.126013  English\n",
       "82          1  3.463852    0.15        p123      L2  0.131732  English\n",
       "46          1  2.858556    0.25        p118  biling  0.113432  Spanish\n",
       "71          0  3.780527    0.10        p121      L2  0.153949  Spanish\n",
       "97          0  3.101587    0.25        p124  biling  0.115026  English\n",
       "31          0  4.063463    0.10        p117      L2  0.110605  Spanish\n",
       "88          1  3.106921    0.30        p123      L2  0.131732  English\n",
       "68          1  3.768125    0.30        p120  biling  0.140621  Spanish"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbas_eng = eng_vsd.copy()\n",
    "cbas_eng[\"Language\"] = \"English\"\n",
    "cbas_spa = spa_vsd[spa_vsd[\"Dom\"]!=\"mono\"].copy()\n",
    "cbas_spa[\"Language\"] = \"Spanish\"\n",
    "cbas_vsd = pd.concat([cbas_eng, cbas_spa])\n",
    "cbas_vsd.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c843f7-3824-4b52-9173-e65f864d4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbas_vsd.to_csv(\"data/cbas_areas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0888660-e33e-4317-ba03-6be630356d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
